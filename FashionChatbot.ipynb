{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Repo de Git"
      ],
      "metadata": {
        "id": "u4gOi3RL6crB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!git clone https://github.com/amandamaduro/FashionAIChatbot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PnS9UT56j1f",
        "outputId": "3fd81682-ed56-4eaf-cae3-6149d9aa18fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FashionAIChatbot'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 5), reused 4 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (13/13), 172.07 KiB | 3.51 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%cd /content/FashionAIChatbot/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5gV8HQm7x7H",
        "outputId": "07ee1d4a-ef3c-4233-a447-2b977dd2d891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FashionAIChatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eptlougrwhza"
      },
      "source": [
        "# Extraer datos de google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWHp8GeJvF1i"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"/content/drive/MyDrive/FashionAIChatbot/Re-PolyVore.tar\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ohdjih2lc1"
      },
      "source": [
        "Verificar que esten todas las imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrg5f8PuwyGR",
        "outputId": "2622973d-71c7-4a50-c317-9203083de0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the directory: 17512\n"
          ]
        }
      ],
      "source": [
        "# prompt: count images from a directory\n",
        "\n",
        "import os\n",
        "\n",
        "def count_images_in_directory(directory):\n",
        "  \"\"\"Counts the number of image files in a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The path to the directory.\n",
        "\n",
        "  Returns:\n",
        "    The number of image files in the directory.\n",
        "  \"\"\"\n",
        "  image_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\"]  # Add more if needed\n",
        "  count = 0\n",
        "  for filename in os.listdir(directory):\n",
        "    if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "# Example usage:\n",
        "directory_path = \"/content/Re-PolyVore/bag\"  # Replace with your directory path\n",
        "image_count = count_images_in_directory(directory_path)\n",
        "print(f\"Number of images in the directory: {image_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdQJL4JN2txu"
      },
      "source": [
        "## **Instalacion de librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QBiudBjy2hUE",
        "outputId": "fbc878a2-1dcd-40bd-9734-43178e309f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
            "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core)\n",
            "  Downloading langsmith-0.1.128-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
            "Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.5-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.128-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.5 langchain-openai-0.2.0 langsmith-0.1.128 openai-1.47.1 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSl-ZnOq5sqA"
      },
      "source": [
        "1. Cargar la imagen del producto en formato base64 data URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3v1YzxFDN-uI",
        "outputId": "554035e9-439e-4cda-cfa8-66c4764fb51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j8BWketRwZvh",
        "outputId": "2c66e44f-1706-44d3-e342-e1eed9c2fd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.5)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.128)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.3.0 langchain-text-splitters-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHxHKk42wHB",
        "outputId": "1118f981-b55e-433f-9566-a9df113a4ab3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.128)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XvCFPB9g0wJo",
        "outputId": "5f99a55d-0e55-499c-88de-8ff067638dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.128)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gzPOqZu5S_H",
        "outputId": "ae6bd6f0-0e71-438d-d68b-4a3c6382ecfd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.128)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsMQ4RR08P1W"
      },
      "source": [
        "##Exportación de API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeXjlV0cMmi4",
        "outputId": "62793ea3-52bc-4d98-9bb4-29349d8e8c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/OPENAI_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d0eca2-e684-47e7-c5ab-2907c7c21102",
        "id": "C0P45cRSwhoN"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/GOOGLE_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/LANGSMITH_API_KEY.env\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEFtvd8D6_1Y",
        "outputId": "06f1c25b-a33b-44af-a329-d4aa2212b53c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export LANGCHAIN_TRACING_V2=true"
      ],
      "metadata": {
        "id": "349VoUGL7HNh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funciones"
      ],
      "metadata": {
        "id": "TiMd27jXwOLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l79cJ5pp5qDg"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "\"\"\"Function to encode images in base64 data URI\n",
        "parameters: image path\n",
        "return: encoded based64 text version\"\"\"\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "#print(encode_image(\"/content/Re-PolyVore/bag/100002074_3.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OpenAI Prompt Simple"
      ],
      "metadata": {
        "id": "CeKo1CNww99A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RccS0vY3v1pn"
      },
      "source": [
        "GPT-4o Prompt mas detallado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YoozKyUJ__1M",
        "outputId": "0c24c4b6-5436-4fbb-d7ad-b5e8c982c57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8705\n",
            "\tPrompt Tokens: 8555\n",
            "\tCompletion Tokens: 150\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00137325\n",
            "**Product Name:** Michael Kors Croc-Embossed Tote\n",
            "\n",
            "**Product Description:** This luxurious tote features a striking croc-embossed design, exuding sophistication and elegance. The bag is accented with gold-tone hardware, showcasing the Michael Kors logo prominently on the front. It includes dual top handles for easy carrying and a detachable shoulder strap for versatility. Its spacious interior allows for ample storage, making it perfect for both everyday use and special occasions.\n",
            "\n",
            "**Product Category:** Handbag/Tote Bag\n",
            "\n",
            "**Style:** Elegant, Modern\n",
            "\n",
            "**Materials:** Faux leather with a croc-embossed finish, gold-tone metal hardware\n",
            "\n",
            "**Dominant Colors:** Rich brown tones with a gradient effect\n",
            "\n",
            "**Fit and Silhouette:** Structured silhouette\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product. Include the product name, product description, product category, style, materials, dominant colors, fit and silhoutte, suitable occasion and recommended season: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bha-if9Fv-hz"
      },
      "source": [
        "GPT-4o-mini. Prompt simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KoESRMHm4rch",
        "outputId": "2517b51c-78d8-42be-a896-7582bb9712e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8630\n",
            "\tPrompt Tokens: 8525\n",
            "\tCompletion Tokens: 105\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0013417499999999998\n",
            "This watch from Daniel Wellington features a classic and elegant design, characterized by its minimalist aesthetic. It has a clean white dial with thin gold hour markers and hands, contributing to its sophisticated appearance. The case is gold-toned, adding a touch of luxury, while the black leather strap provides a timeless contrast, ensuring versatility for various occasions. This watch combines functionality with style, making it suitable for both casual and formal outfits. Its understated elegance makes it a perfect accessory for anyone looking to enhance their wardrobe with a chic timepiece.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(\"/content/Re-PolyVore/watches/139069134_7.jpg\")\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gemini Prompt Simple"
      ],
      "metadata": {
        "id": "v7bwf1D2xSBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-_15-E71gSy",
        "outputId": "04e23d2c-c291-488a-cc3d-86c99d4b7d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This statement necklace features a bold, geometric design with a modern, edgy feel.  The black and gold color scheme adds a touch of sophistication and glamour. The sharp, angular shapes create a striking contrast against the delicate chain, making it a perfect choice for a night out or a special occasion. It's also versatile enough to be dressed up or down, depending on the occasion. The necklace is sure to turn heads and make a statement.  I would recommend pairing it with a simple black dress or a white blouse and jeans for a chic and modern look. \n",
            "\n",
            "Tokens Used: 387\n",
            "\tPrompt Tokens: 274\n",
            "\tCompletion Tokens: 113\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0\n",
            "{'input_tokens': 274, 'output_tokens': 113, 'total_tokens': 387}\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "\n",
        "image_path= \"/content/Re-PolyVore/necklace/100060207_4.jpg\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", max_output_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"You are a professional stylist and fashion consultant. Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke([message])\n",
        "  print(response.content)\n",
        "  print(cb)\n",
        "print(response.usage_metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0U3huDykUPm"
      },
      "source": [
        "##**En español**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3c0T4j6HkQ2_",
        "outputId": "03b454ba-2891-4751-9f92-5a6a95fd21ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-d0c3c1083ca9>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m\"language\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Spanish\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Set the output language to Spanish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"format_instructions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;34m\"image_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     })\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure that response is formatted as JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_data' is not defined"
          ]
        }
      ],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"El nombre del producto de moda mostrado en la imagen\")\n",
        "    description: str = Field(description=\"La descripción del producto de moda mostrado en la imagen\")\n",
        "    category: str = Field(description=\"La categoría del producto de moda mostrado en la imagen (ej. vestido, pantalones, blusa, chaqueta, etc.)\")\n",
        "    style: str = Field(description=\"El estilo del producto de moda mostrado en la imagen, puede elegir más de uno (ej. formal, casual, deportivo, etc.)\")\n",
        "    materials: str = Field(description=\"Los materiales del producto de moda mostrado en la imagen (ej. algodón, seda, cuero, etc.)\")\n",
        "    color: str = Field(description=\"Los colores dominantes del producto de moda mostrado en la imagen\")\n",
        "    fit_silhouette: str = Field(description=\"El ajuste y la silueta del producto de moda mostrado en la imagen (ej. ajustado, suelto, recto, etc.)\")\n",
        "    occasion: str = Field(description=\"La ocasión adecuada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. evento formal, uso diario, vacaciones, etc.)\")\n",
        "    season: str = Field(description=\"La temporada recomendada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. primavera, verano, otoño, invierno, todas las temporadas)\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"Eres un estilista profesional y asesor de moda. Devuelve las descripciones del producto de moda solicitado en {language}.\\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    # Invoke the chain with the language set to Spanish\n",
        "    response = chain.invoke({\n",
        "        \"language\": \"Spanish\",  # Set the output language to Spanish\n",
        "        \"format_instructions\": parser.get_format_instructions(),\n",
        "        \"image_data\": image_data\n",
        "    })\n",
        "    print(response.model_dump_json(indent=2))  # Ensure that response is formatted as JSON\n",
        "    print(cb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Generacion de descripciones de productos con formato JSON**"
      ],
      "metadata": {
        "id": "INTsjTX3xqdl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-rNFXYCvShl9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.callbacks import CallbackManager\n",
        "\n",
        "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "# image_path= \"/content/prueba/4207948.jpg\"\n",
        "\n",
        "# image_data = encode_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JAJPZ0cBLfrg"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, field_validator, ValidationError, model_validator\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from typing import Any, Dict\n",
        "import re\n",
        "import json\n",
        "\n",
        "# We define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"The name of the fashion product shown in the image\")\n",
        "    description: str = Field(description=\"The description of the fashion product shown in the image\")\n",
        "    category: str = Field(description=\"The category of the fashion product shown in the image (e.g. dress, pants, blouse, jacket, etc)\")\n",
        "    style: str = Field(description=\"The style of the fashion product shown in the image, you can choose more than one (e.g. formal, casual, sporty, etc.)\")\n",
        "    materials: str = Field(description=\"The materials of the fashion product shown in the image (e.g. cotton, silk, leather, etc.)\")\n",
        "    color: str = Field(description=\"The dominant colors of the fashion product shown in the image\")\n",
        "    fit_silhouette: str = Field(description=\"The fit and silhouette of the fashion product shown in the image (e.g. fitted, loose, straight, etc.). If nothing applies, set it to N/A\")\n",
        "    occasion: str = Field(description=\"The suitable occasion for the fashion product shown in the image, you can choose more than one (e.g. formal event, everyday wear, vacation, etc.)\")\n",
        "    season: str = Field(description=\"The recommended season for the fashion product shown in the image, you can choose more than one (e.g. spring, summer, fall, winter, all seasons)\")\n",
        "\n",
        "    @field_validator('*', mode=\"before\")\n",
        "    @classmethod\n",
        "    def validate_strings(cls, value: Any, field: Any) -> str:\n",
        "        \"\"\"Valida que todos los campos sean strings, y convierte si es necesario.\"\"\"\n",
        "        if isinstance(value, list):\n",
        "            # Aquí manejamos la conversión de listas a strings\n",
        "            value = ', '.join(value)\n",
        "\n",
        "        if not isinstance(value, str):\n",
        "            raise ValueError(f\"The field '{field.name}' must be a string.\")\n",
        "\n",
        "        # Reemplazar operadores de concatenación inválidos (ejemplo: \" + \")\n",
        "        value_str = re.sub(r'\\s*\\+\\s*', ' ', value)\n",
        "\n",
        "        # Escapar comillas dobles dentro de strings\n",
        "        return value_str.replace('\"', '\\\"')\n",
        "\n",
        "#-----------------------------PARA PROBAR EL PYDANTIC MODEL----------------------------------------\n",
        "# Ejemplo de uso\n",
        "# ejemplos = [\n",
        "#     FashionProduct(name='Fendi Peekaboo' + 'ISeeU Mini Bag', description='This Fendi Peekaboo ISeeU Mini Bag is crafted from pink leather and features a top handle, a detachable and adjustable shoulder strap, a top zip closure, a signature peekaboo flap closure, silver-tone hardware, a front logo plaque, and a crystal-embellished charm.', category='Handbag', style='Casual', materials='Leather', color='Pink', fit_silhouette='N/A', occasion='Everyday, Casual', season='All Seasons'),\n",
        "#     FashionProduct(name='Clear Acrylic Clutch', description='A clear acrylic clutch with a gold chain strap and a gold clasp. It is perfect for carrying your essentials for a night out.', category='Clutch', style=['Formal', 'Evening'], materials='Acrylic, Metal', color='Clear, Gold', fit_silhouette='N/A', occasion='Formal Event, Night Out', season='All Seasons'),\n",
        "#     FashionProduct(name='Kotur Clutch', description='This clutch is \"made\" of black and white striped acrylic with a gold bird-shaped clasp. It is perfect for evening wear.', category='Clutch', style='Formal', materials='Acrylic, Gold', color='Black and White', fit_silhouette='N/A', occasion='Formal event, Evening wear', season='All seasons'),\n",
        "#     FashionProduct(name='Quilted Patent Leather Tote Bag', description='This tote bag is made of white patent leather with a quilted design. It features a top handle and a detachable chain strap. It has a gold-tone hardware and a heart-shaped charm on the front.', category='Handbag', style='Classic', materials='Patent Leather', color='White', fit_silhouette='N/A', occasion='Everyday, Formal, Work', season='All Seasons'),\n",
        "#     FashionProduct(name='Leather Chain Strap Crossbody Bag', description='This is a small crossbody bag with a chain strap. It is made of brown leather and has a flap closure. The bag is perfect for everyday wear and can be dressed up or down.', category='Bag', style='Casual', materials='Leather', color='Brown', fit_silhouette='N/A', occasion='Everyday, Casual', season='All Seasons')\n",
        "# ]\n",
        "\n",
        "# # Imprimir los productos validados\n",
        "# for product in ejemplos:\n",
        "#     print(product.model_dump_json(indent=2))\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"You are a professional stylist and fashion consultant. Return the requested response fashion product object in {language}. You must use JSON Format. \\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# with get_openai_callback() as cb:\n",
        "#   response= chain.invoke(\n",
        "#     {\"language\":\"English\",\n",
        "#       \"format_instructions\":parser.get_format_instructions(),\n",
        "#       \"image_data\":image_data}\n",
        "#     )\n",
        "#   print(cb)\n",
        "#   print(response)\n",
        "# #print(response)\n",
        "# print(response.model_dump_json(indent=2))\n",
        "\n",
        "\n",
        "# print(chain.invoke({\"language\":\"English\",\n",
        "#                     \"format_instructions\":parser.get_format_instructions(),\n",
        "#                     \"image_data\":image_data}).model_dump_json(indent=2),)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHrw1YM81jDz"
      },
      "source": [
        "##Procesamiento en Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk2O4Rg0DSEW"
      },
      "source": [
        "\n",
        "Procesamiento paralelo con verificacion de que en ningun batch hayan duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr3tPMPpDXDz",
        "outputId": "1e29eb21-e843-4283-ad3b-8e46ab6687f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing batch 1: Invalid json output: \n",
            "Retrying...\n",
            "Error processing batch 1: Invalid json output: \n",
            "Retrying...\n",
            "Error processing batch 1: Invalid json output: \n",
            "Max retries reached. Skipping this batch.\n",
            "Waiting 30 seconds to avoid rate limits\n",
            "Total processing time: 72.17 seconds for 0 images.\n",
            "Error processing batch 2: Invalid json output: ```json\n",
            "{\"name\": \"Kate Spade \"I Need A Vacation\" Tote Bag\", \"description\": \"This fun and stylish tote bag features a vibrant blue and green palm tree print with the phrase \\\"I Need A Vacation\\\" in white lettering. It's perfect for carrying all your essentials for a day at the beach or a weekend getaway.\", \"category\": \"Tote Bag\", \"style\": \"Casual\", \"materials\": \"Canvas\", \"color\": \"Blue, Green, White\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Everyday, Vacation\", \"season\": \"Spring, Summer\"}\n",
            "```\n",
            "Retrying...\n",
            "Error processing batch 2: Invalid json output: ```json\n",
            "{\"name\": \"Kate Spade \"I Need A Vacation\" Tote Bag\", \"description\": \"This stylish tote bag features a playful design with palm trees and the phrase \\\"I Need A Vacation\\\" printed on a light blue background. It's perfect for carrying your essentials to the beach, pool, or on your next vacation.\", \"category\": \"Tote Bag\", \"style\": \"Casual\", \"materials\": \"Canvas\", \"color\": \"Light Blue, White, Green\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Vacation, Everyday\", \"season\": \"Spring, Summer\"}\n",
            "```\n",
            "Retrying...\n",
            "Error processing batch 2: Invalid json output: ```json\n",
            "{\"name\": \"Kate Spade \"I Need a Vacation\" Tote Bag\", \"description\": \"This tote bag features a light blue canvas with a watercolor-style print of palm trees and the phrase \\\"I Need a Vacation.\\\" It has a spacious interior and is perfect for carrying all your essentials.\", \"category\": \"Tote Bag\", \"style\": \"Casual\", \"materials\": \"Canvas\", \"color\": \"Light Blue, Green, White\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Everyday, Vacation\", \"season\": \"All Seasons\"}\n",
            "```\n",
            "Max retries reached. Skipping this batch.\n",
            "Waiting 30 seconds to avoid rate limits\n",
            "Total processing time: 148.38 seconds for 0 images.\n",
            "Batch 3 processed in 18.87 seconds, total token: 85633 (prompt token:75510, completion token:10123)\n",
            "Waiting 30 seconds to avoid rate limits\n",
            "Total processing time: 197.54 seconds for 90 images.\n",
            "Error processing batch 4: Invalid json output: ```json\n",
            "{\"name\": \"Alexander McQueen  \" + \"Black  \" + \"Small  \" + \"Box Bag\", \"description\": \"This Alexander McQueen  \" + \"Black  \" + \"Small  \" + \"Box Bag is a stylish and sophisticated handbag that is perfect for any occasion. Made from high-quality leather, this bag features a top handle, a detachable chain strap, and a signature lock and key charm. It is spacious enough to carry all of your essentials and is sure to turn heads wherever you go.\", \"category\": \"Handbag\", \"style\": \"Formal, Casual\", \"materials\": \"Leather\", \"color\": \"Black\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Everyday wear, Formal event\", \"season\": \"All seasons\"}\n",
            "```\n",
            "Retrying...\n",
            "Error processing batch 4: Invalid json output: ```json\n",
            "{\"name\": \"Marc Jacobs  \" + \"The  \" + \"Stam Bag\", \"description\": \"The Marc Jacobs Stam Bag is a classic handbag that is both stylish and functional. It is made of high-quality leather and features a top zip closure, two top handles, and an adjustable shoulder strap. The bag is spacious enough to carry all your essentials, and its sleek design makes it perfect for any occasion.\", \"category\": \"Handbag\", \"style\": \"Classic, Casual, Chic\", \"materials\": \"Leather\", \"color\": \"Light Blue\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Everyday, Shopping, Brunch, Work\", \"season\": \"All Seasons\"}\n",
            "```\n",
            "Retrying...\n",
            "Batch 4 processed in 46.59 seconds, total token: 85764 (prompt token:75510, completion token:10254)\n",
            "Waiting 30 seconds to avoid rate limits\n",
            "Total processing time: 274.46 seconds for 180 images.\n",
            "Batch 5 processed in 17.87 seconds, total token: 85943 (prompt token:75510, completion token:10433)\n",
            "Total processing time: 292.57 seconds for 270 images.\n",
            "Results have been saved to /content/FashionAIChatbot/results.json\n",
            "Total de imágenes procesadas: 270\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "import time\n",
        "\n",
        "total_imagenes_procesadas= 0\n",
        "# Variable global para almacenar el raw_output de cada batch\n",
        "raw_outputs_global = []\n",
        "max_retries = 3\n",
        "\n",
        "# File to store processed image paths to avoid duplicates\n",
        "processed_images_file = \"/content/FashionAIChatbot/processed_images.json\"\n",
        "\n",
        "# Load the list of already processed images\n",
        "if os.path.exists(processed_images_file):\n",
        "    with open(processed_images_file, 'r') as f:\n",
        "        processed_images = set(json.load(f))  # Use a set for fast lookups\n",
        "else:\n",
        "    processed_images = set()\n",
        "\n",
        "# JSON file to store the results\n",
        "results_file = \"/content/FashionAIChatbot/results.json\"\n",
        "\n",
        "#Load existing results if the file exists\n",
        "if os.path.exists(results_file):\n",
        "    with open(results_file, 'r') as f:\n",
        "        all_results = json.load(f)\n",
        "else:\n",
        "    all_results = []\n",
        "\n",
        "#print(all_results)\n",
        "\n",
        "def get_unprocessed_images(image_directory: str, max_images: int = 1000) -> List[str]:\n",
        "    \"\"\"Get all unprocessed images from the directory.\"\"\"\n",
        "    image_files = [\n",
        "        os.path.join(image_directory, f)\n",
        "        for f in os.listdir(image_directory)\n",
        "        if f.endswith(('.jpg', '.jpeg', '.png')) and os.path.join(image_directory, f) not in processed_images\n",
        "    ]\n",
        "    return image_files[:max_images]\n",
        "\n",
        "\n",
        "def prepare_batch_data(image_paths: List[str]) -> List[Dict[str, str]]:\n",
        "    \"\"\"Prepare batch data for LangChain.\"\"\"\n",
        "    batch_data = []\n",
        "    for image_path in image_paths:\n",
        "        image_data = encode_image(image_path)  # Encode image\n",
        "        batch_data.append({\n",
        "            \"language\": \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions(),\n",
        "            \"image_data\": image_data,\n",
        "            \"image_path\": image_path\n",
        "            #\"image_base64\": image_data  # Optionally add base64 string to results\n",
        "        })\n",
        "    return batch_data\n",
        "\n",
        "\n",
        "def process_image_batches_with_langchain(image_directory: str, batch_size: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Process images in batches, ensuring no duplicate processing.\"\"\"\n",
        "\n",
        "    # Start time for the entire process\n",
        "    start_time_total = time.time()\n",
        "\n",
        "    # Get all unprocessed images\n",
        "    unprocessed_images = get_unprocessed_images(image_directory, max_images=350)\n",
        "\n",
        "    global all_results  # Acceder a la variable global para agregar resultados\n",
        "    global total_imagenes_procesadas\n",
        "    global raw_outputs_global  # Variable global para almacenar los raw_outputs de cada batch\n",
        "    total_tokens = 0\n",
        "    total_prompt_tokens = 0\n",
        "    total_completion_tokens = 0\n",
        "\n",
        "    # Process images in batches\n",
        "    for i in range(0, len(unprocessed_images), batch_size):\n",
        "        batch = unprocessed_images[i:i + batch_size]\n",
        "        batch_data = prepare_batch_data(batch)\n",
        "        # print(f\"BATCH {i//batch_size + 1}: {len(batch_data)} imágenes procesadas.\")\n",
        "        #print(\"BATCH DATA:\", batch_data)\n",
        "        retries = 0  # Contador de reintentos\n",
        "\n",
        "        num_imagenes_procesadas = len(batch_data)\n",
        "\n",
        "        # Start time for the current batch\n",
        "        start_time_batch = time.time()\n",
        "\n",
        "        while retries < max_retries:\n",
        "            try:\n",
        "              with get_openai_callback() as cb:\n",
        "                # Use the LangChain .batch method to process the batch\n",
        "                results = chain.batch(batch_data)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                retries += 1  # Incrementar el contador de reintentos\n",
        "                print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
        "                if retries < max_retries:\n",
        "                    print(\"Retrying...\")\n",
        "                    #time.sleep(30)  # Esperar 30 segundos antes de reintentar\n",
        "                else:\n",
        "                    print(\"Max retries reached. Skipping this batch.\")\n",
        "                    continue  # Salir del bucle while y continuar con el siguiente batch\n",
        "        # Procesar los resultados si fueron exitosos\n",
        "        if retries < max_retries:\n",
        "            # Process the corrected results\n",
        "            for result, image_info in zip(results, batch_data):\n",
        "                #print(\"entro aqui\")\n",
        "                raw_output = None\n",
        "                try:\n",
        "                    # Get raw_output before parsing\n",
        "                    raw_output = result\n",
        "                    #raw_outputs_global.append(raw_output)  # Almacenar el raw_output en la variable global\n",
        "\n",
        "                    # Convert the corrected result to a Pydantic model\n",
        "                    result_dict = result.model_dump()\n",
        "                    result_dict[\"image_path\"] = image_info[\"image_path\"]\n",
        "                    all_results.append(result_dict)\n",
        "                except ValidationError as ve:\n",
        "                    print(f\"Validation error for image {image_info['image_path']}: {ve.errors()}\")\n",
        "                except Exception as e:\n",
        "                    # Indicar que la imagen no se procesó correctamente y mostrar el raw_output\n",
        "                    print(f\"Error parsing result for image {image_info['image_path']}: {e}\")\n",
        "                    print(f\"Raw output for this image: {raw_output}\")\n",
        "\n",
        "            # Sumar el uso de tokens, prompt y completion\n",
        "            total_tokens += cb.total_tokens\n",
        "            total_prompt_tokens += cb.prompt_tokens\n",
        "            total_completion_tokens += cb.completion_tokens\n",
        "\n",
        "            # Update the list of processed images\n",
        "            processed_images.update(batch)\n",
        "\n",
        "            # Save the updated processed images list\n",
        "            with open(processed_images_file, 'w') as f:\n",
        "                json.dump(list(processed_images), f, indent=2)\n",
        "\n",
        "            # End time for the batch\n",
        "            end_time_batch = time.time()\n",
        "            batch_duration = end_time_batch - start_time_batch\n",
        "\n",
        "            print(f\"Batch {i // batch_size + 1} processed in {batch_duration:.2f} seconds, total token: {total_tokens} (prompt token:{total_prompt_tokens}, completion token:{total_completion_tokens})\")\n",
        "\n",
        "            total_imagenes_procesadas += num_imagenes_procesadas\n",
        "\n",
        "            #Reinicio cantidad tokens:\n",
        "            total_tokens = 0\n",
        "            total_prompt_tokens = 0\n",
        "            total_completion_tokens = 0\n",
        "\n",
        "        # Check if it's the last batch, if not, wait for 30 seconds\n",
        "        if i + batch_size < len(unprocessed_images):\n",
        "            time.sleep(30)  # Wait for 30 seconds before processing the next batch\n",
        "            print(\"Waiting 30 seconds to avoid rate limits\")\n",
        "        # End time for the entire process\n",
        "        end_time_total = time.time()\n",
        "        total_duration = end_time_total - start_time_total\n",
        "        print(f\"Total processing time: {total_duration:.2f} seconds for {total_imagenes_procesadas} images.\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_directory = \"/content/Re-PolyVore/bag\"\n",
        "batch_size = 70\n",
        "results = process_image_batches_with_langchain(image_directory, batch_size)\n",
        "\n",
        "\n",
        "# no_procesadas=get_unprocessed_images(image_directory)\n",
        "# print(\"resultado de get_unprocessed_images: \", no_procesadas)\n",
        "\n",
        "#\n",
        "\n",
        "# for i in range(0, len(no_procesadas), batch_size):\n",
        "#     batch = no_procesadas[i:i + batch_size]\n",
        "#     batch_data = prepare_batch_data(batch)\n",
        "\n",
        "#     print(f\"BATCH {i//batch_size + 1}: {num_imagenes_procesadas} imágenes procesadas.\")\n",
        "#     print(\"BATCH DATA:\", batch_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Save results as JSON in a file\n",
        "with open(results_file, \"w\") as json_file:\n",
        "    json.dump(all_results, json_file, indent=2)\n",
        "\n",
        "print(f\"Results have been saved to {results_file}\")\n",
        "\n",
        "# Imprimir el raw_output al final de la ejecución\n",
        "# print(f\"Raw outputs from all batches: {raw_outputs_global}\")\n",
        "\n",
        "# Al final, imprimir el total de imágenes procesadas\n",
        "print(f\"Total de imágenes procesadas: {total_imagenes_procesadas}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FashionAIChatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vriO610ndq1B",
        "outputId": "bfbe9cf8-f95d-40ff-a7ae-40d216eb57fa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FashionAIChatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add processed_images.json results.json\n",
        "!git commit -m \"updated processed_images.json and results.json (5128 images)\"\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9e4cUaO7PzX",
        "outputId": "c92e6834-50b9-4209-eb25-f4ff1c164450"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main fe3b08c] updated processed_images.json and results.json (5128 images)\n",
            " 2 files changed, 23578 insertions(+), 2648 deletions(-)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 152.57 KiB | 2.09 MiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/amandamaduro/FashionAIChatbot.git\n",
            "   c7846df..fe3b08c  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ILUfhSCprL",
        "outputId": "30d427f7-7ce3-46bd-d629-2f6a33c30d9b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}