{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4gOi3RL6crB"
      },
      "source": [
        "##Repo de Git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PnS9UT56j1f",
        "outputId": "d15a164d-ab62-4fac-d181-e9172ef78c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FashionAIChatbot'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "Receiving objects: 100% (101/101), 2.73 MiB | 8.97 MiB/s, done.\n",
            "remote: Total 101 (delta 70), reused 53 (delta 28), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amandamaduro/FashionAIChatbot.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5gV8HQm7x7H",
        "outputId": "f6e94749-a314-483c-8a39-0ce79cfee1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FashionAIChatbot\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FashionAIChatbot/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eptlougrwhza"
      },
      "source": [
        "# Extraer datos de google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWHp8GeJvF1i"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"/content/drive/MyDrive/FashionAIChatbot/Re-PolyVore.tar\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ohdjih2lc1"
      },
      "source": [
        "Verificar que esten todas las imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrg5f8PuwyGR",
        "outputId": "27c83b57-c225-466d-e7f0-fd7635565e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the directory: 4563\n"
          ]
        }
      ],
      "source": [
        "# prompt: count images from a directory\n",
        "\n",
        "import os\n",
        "\n",
        "def count_images_in_directory(directory):\n",
        "  \"\"\"Counts the number of image files in a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The path to the directory.\n",
        "\n",
        "  Returns:\n",
        "    The number of image files in the directory.\n",
        "  \"\"\"\n",
        "  image_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\"]  # Add more if needed\n",
        "  count = 0\n",
        "  for filename in os.listdir(directory):\n",
        "    if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "# Example usage:\n",
        "directory_path = \"/content/Re-PolyVore/earrings\"  # Replace with your directory path\n",
        "image_count = count_images_in_directory(directory_path)\n",
        "print(f\"Number of images in the directory: {image_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdQJL4JN2txu"
      },
      "source": [
        "## **Instalacion de librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QBiudBjy2hUE",
        "outputId": "347dd7f3-df78-45e5-f3db-ee8cac7bb8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.50.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3v1YzxFDN-uI",
        "outputId": "2350f469-3793-4726-d1d7-528331ad0396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j8BWketRwZvh",
        "outputId": "109e14c3-7472-40b2-c501-3ceab50b97be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LnHxHKk42wHB",
        "outputId": "ce880de5-465b-40a4-f9b5-f9ccd092e06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.129)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XvCFPB9g0wJo",
        "outputId": "8c9582ca-3d3b-47c7-900e-c2b5f14958b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.129)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gzPOqZu5S_H",
        "outputId": "c974b0d9-bb83-4e94-9be7-b1adffe20ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.1.129)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.7)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsMQ4RR08P1W"
      },
      "source": [
        "##Exportación de API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeXjlV0cMmi4",
        "outputId": "62793ea3-52bc-4d98-9bb4-29349d8e8c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/OPENAI_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0P45cRSwhoN",
        "outputId": "fa026687-1f0d-4e88-9058-26d9e0140403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/GOOGLE_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEFtvd8D6_1Y",
        "outputId": "06f1c25b-a33b-44af-a329-d4aa2212b53c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/LANGSMITH_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "349VoUGL7HNh"
      },
      "outputs": [],
      "source": [
        "!export LANGCHAIN_TRACING_V2=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiMd27jXwOLW"
      },
      "source": [
        "##Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l79cJ5pp5qDg"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "\"\"\"Function to encode images in base64 data URI\n",
        "parameters: image path\n",
        "return: encoded based64 text version\"\"\"\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "#print(encode_image(\"/content/Re-PolyVore/bag/100002074_3.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeKo1CNww99A"
      },
      "source": [
        "##OpenAI Prompt Simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RccS0vY3v1pn"
      },
      "source": [
        "GPT-4o Prompt mas detallado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YoozKyUJ__1M",
        "outputId": "0c24c4b6-5436-4fbb-d7ad-b5e8c982c57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8705\n",
            "\tPrompt Tokens: 8555\n",
            "\tCompletion Tokens: 150\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00137325\n",
            "**Product Name:** Michael Kors Croc-Embossed Tote\n",
            "\n",
            "**Product Description:** This luxurious tote features a striking croc-embossed design, exuding sophistication and elegance. The bag is accented with gold-tone hardware, showcasing the Michael Kors logo prominently on the front. It includes dual top handles for easy carrying and a detachable shoulder strap for versatility. Its spacious interior allows for ample storage, making it perfect for both everyday use and special occasions.\n",
            "\n",
            "**Product Category:** Handbag/Tote Bag\n",
            "\n",
            "**Style:** Elegant, Modern\n",
            "\n",
            "**Materials:** Faux leather with a croc-embossed finish, gold-tone metal hardware\n",
            "\n",
            "**Dominant Colors:** Rich brown tones with a gradient effect\n",
            "\n",
            "**Fit and Silhouette:** Structured silhouette\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product. Include the product name, product description, product category, style, materials, dominant colors, fit and silhoutte, suitable occasion and recommended season: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bha-if9Fv-hz"
      },
      "source": [
        "GPT-4o-mini. Prompt simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KoESRMHm4rch",
        "outputId": "2517b51c-78d8-42be-a896-7582bb9712e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8630\n",
            "\tPrompt Tokens: 8525\n",
            "\tCompletion Tokens: 105\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0013417499999999998\n",
            "This watch from Daniel Wellington features a classic and elegant design, characterized by its minimalist aesthetic. It has a clean white dial with thin gold hour markers and hands, contributing to its sophisticated appearance. The case is gold-toned, adding a touch of luxury, while the black leather strap provides a timeless contrast, ensuring versatility for various occasions. This watch combines functionality with style, making it suitable for both casual and formal outfits. Its understated elegance makes it a perfect accessory for anyone looking to enhance their wardrobe with a chic timepiece.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(\"/content/Re-PolyVore/watches/139069134_7.jpg\")\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7bwf1D2xSBB"
      },
      "source": [
        "##Gemini Prompt Simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-_15-E71gSy",
        "outputId": "04e23d2c-c291-488a-cc3d-86c99d4b7d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This statement necklace features a bold, geometric design with a modern, edgy feel.  The black and gold color scheme adds a touch of sophistication and glamour. The sharp, angular shapes create a striking contrast against the delicate chain, making it a perfect choice for a night out or a special occasion. It's also versatile enough to be dressed up or down, depending on the occasion. The necklace is sure to turn heads and make a statement.  I would recommend pairing it with a simple black dress or a white blouse and jeans for a chic and modern look. \n",
            "\n",
            "Tokens Used: 387\n",
            "\tPrompt Tokens: 274\n",
            "\tCompletion Tokens: 113\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0\n",
            "{'input_tokens': 274, 'output_tokens': 113, 'total_tokens': 387}\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "\n",
        "image_path= \"/content/Re-PolyVore/necklace/100060207_4.jpg\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", max_output_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"You are a professional stylist and fashion consultant. Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke([message])\n",
        "  print(response.content)\n",
        "  print(cb)\n",
        "print(response.usage_metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0U3huDykUPm"
      },
      "source": [
        "##**En español**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c0T4j6HkQ2_",
        "outputId": "0ca4f334-7a21-4694-c714-51e52e11eb04"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'llm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d0c3c1083ca9>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m ])\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mget_openai_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
          ]
        }
      ],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"El nombre del producto de moda mostrado en la imagen\")\n",
        "    description: str = Field(description=\"La descripción del producto de moda mostrado en la imagen\")\n",
        "    category: str = Field(description=\"La categoría del producto de moda mostrado en la imagen (ej. vestido, pantalones, blusa, chaqueta, etc.)\")\n",
        "    style: str = Field(description=\"El estilo del producto de moda mostrado en la imagen, puede elegir más de uno (ej. formal, casual, deportivo, etc.)\")\n",
        "    materials: str = Field(description=\"Los materiales del producto de moda mostrado en la imagen (ej. algodón, seda, cuero, etc.)\")\n",
        "    color: str = Field(description=\"Los colores dominantes del producto de moda mostrado en la imagen\")\n",
        "    fit_silhouette: str = Field(description=\"El ajuste y la silueta del producto de moda mostrado en la imagen (ej. ajustado, suelto, recto, etc.)\")\n",
        "    occasion: str = Field(description=\"La ocasión adecuada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. evento formal, uso diario, vacaciones, etc.)\")\n",
        "    season: str = Field(description=\"La temporada recomendada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. primavera, verano, otoño, invierno, todas las temporadas)\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"Eres un estilista profesional y asesor de moda. Devuelve las descripciones del producto de moda solicitado en {language}.\\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    # Invoke the chain with the language set to Spanish\n",
        "    response = chain.invoke({\n",
        "        \"language\": \"Spanish\",  # Set the output language to Spanish\n",
        "        \"format_instructions\": parser.get_format_instructions(),\n",
        "        \"image_data\": image_data\n",
        "    })\n",
        "    print(response.model_dump_json(indent=2))  # Ensure that response is formatted as JSON\n",
        "    print(cb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INTsjTX3xqdl"
      },
      "source": [
        "##**Generacion de descripciones de productos con formato JSON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-rNFXYCvShl9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.callbacks import CallbackManager\n",
        "\n",
        "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C26Rfaxk22gy"
      },
      "outputs": [],
      "source": [
        "image_path= \"/content/Re-PolyVore/earrings/100060207_6.jpg\"\n",
        "\n",
        "image_data = encode_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JAJPZ0cBLfrg"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, field_validator, ValidationError, ValidationInfo\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from typing import Any, Dict\n",
        "import re\n",
        "import json\n",
        "\n",
        "# We define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"Create a name for the fashion product shown in the image. Do not invent the brand name if it is not shown on the product image.\")\n",
        "    description: str = Field(description=\"The description of the fashion product shown in the image\")\n",
        "    category: str = Field(description=\"The category of the fashion product shown in the image (e.g. dress, pants, blouse, jacket, etc)\")\n",
        "    style: str = Field(description=\"The of the fashion product shown in the image, you can choose more than one (e.g. formal, casual, sporty, etc.)\")\n",
        "    materials: str = Field(description=\"The materials of the fashion product shown in the image (e.g. cotton, silk, leather, etc.)\")\n",
        "    color: str = Field(description=\"The dominant colors of the fashion product shown in the image\")\n",
        "    fit_silhouette: str = Field(description=\"The fit and silhouette of the fashion product shown in the image (e.g. fitted, loose, straight, etc.). If nothing applies, set it to N/A\")\n",
        "    occasion: str = Field(description=\"The suitable occasion for the fashion product shown in the image, you can choose more than one (e.g. formal event, everyday wear, vacation, etc.)\")\n",
        "    season: str = Field(description=\"The recommended season for the fashion product shown in the image, you can choose more than one (e.g. spring, summer, fall, winter, all seasons)\")\n",
        "\n",
        "    @field_validator('*', mode=\"before\")\n",
        "    @classmethod\n",
        "    def validate_strings(cls, value: Any, info: ValidationInfo) -> str:\n",
        "        \"\"\"Valida que todos los campos sean strings, y convierte si es necesario.\"\"\"\n",
        "        if isinstance(value, list):\n",
        "            # Aquí manejamos la conversión de listas a strings\n",
        "            value = ', '.join(value)\n",
        "\n",
        "        if not isinstance(value, str):\n",
        "            raise ValueError(f\"The field '{info.field_name}' must be a string.\")\n",
        "\n",
        "        # Validar si el campo 'name' es 'N/A' o 'null'\n",
        "        if info.field_name == 'name' and value.strip().lower() in {'n/a', 'null'}:\n",
        "            raise ValueError(\"The 'name' field cannot be 'N/A' or 'null'.\")\n",
        "\n",
        "        # Reemplazar operadores de concatenación inválidos (ejemplo: \" + \")\n",
        "        value_str = re.sub(r'\\s*\\+\\s*', ' ', value)\n",
        "\n",
        "        # Escapar comillas dobles dentro de strings\n",
        "        return value_str.replace('\"', '\\\"')\n",
        "\n",
        "# -----------------------------PARA PROBAR EL PYDANTIC MODEL----------------------------------------\n",
        "# Ejemplo de uso\n",
        "# ejemplos = [\n",
        "#     FashionProduct(name=\"bag\",description=\"A stylish jacket\",category=\"jacket\",style=\"casual\",materials=\"leather\",color=\"black\",fit_silhouette=\"fitted\",occasion=\"everyday wear\",season=\"fall\"),\n",
        "#     FashionProduct(name='Clear Acrylic Clutch', description='A clear acrylic clutch with a gold chain strap and a gold clasp. It is perfect for carrying your essentials for a night out.', category='Clutch', style=['Formal', 'Evening'], materials='Acrylic, Metal', color='Clear, Gold', fit_silhouette='N/A', occasion='Formal Event, Night Out', season='All Seasons'),\n",
        "#     FashionProduct(name='Kotur Clutch', description='This clutch is \"made\" of black and white striped acrylic with a gold bird-shaped clasp. It is perfect for evening wear.', category='Clutch', style='Formal', materials='Acrylic, Gold', color='Black and White', fit_silhouette='N/A', occasion='Formal event, Evening wear', season='All seasons'),\n",
        "#     FashionProduct(name='Quilted Patent Leather Tote Bag', description='This tote bag is made of white patent leather with a quilted design. It features a top handle and a detachable chain strap. It has a gold-tone hardware and a heart-shaped charm on the front.', category='Handbag', style='Classic', materials='Patent Leather', color='White', fit_silhouette='N/A', occasion='Everyday, Formal, Work', season='All Seasons'),\n",
        "#     FashionProduct(name='Leather Chain Strap Crossbody Bag', description='This is a small crossbody bag with a chain strap. It is made of brown leather and has a flap closure. The bag is perfect for everyday wear and can be dressed up or down.', category='Bag', style='Casual', materials='Leather', color='Brown', fit_silhouette='N/A', occasion='Everyday, Casual', season='All Seasons')\n",
        "# ]\n",
        "\n",
        "# # Imprimir los productos validados\n",
        "# try:\n",
        "#   for product in ejemplos:\n",
        "#       print(product.model_dump_json(indent=2))\n",
        "# except ValidationError as e:\n",
        "#   print(e)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"You are a professional stylist and fashion consultant. Return the requested response fashion product object in {language}. You must use JSON Format. \\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# with get_openai_callback() as cb:\n",
        "#   response= chain.invoke(\n",
        "#     {\"language\":\"English\",\n",
        "#       \"format_instructions\":parser.get_format_instructions(),\n",
        "#       \"image_data\":image_data}\n",
        "#     )\n",
        "#   print(cb)\n",
        "#   print(response)\n",
        "# #print(response)\n",
        "# print(response.model_dump_json(indent=2))\n",
        "\n",
        "\n",
        "# print(chain.invoke({\"language\":\"English\",\n",
        "#                     \"format_instructions\":parser.get_format_instructions(),\n",
        "#                     \"image_data\":image_data}).model_dump_json(indent=2),)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHrw1YM81jDz"
      },
      "source": [
        "##Procesamiento en Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk2O4Rg0DSEW"
      },
      "source": [
        "\n",
        "Procesamiento paralelo con verificacion de que en ningun batch hayan duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr3tPMPpDXDz",
        "outputId": "450b81b5-684f-4e83-e946-5d82540409cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 1 processed in 17.41 seconds, total token: 77633 (prompt token:68400, completion token:9233)\n",
            "Total processing time: 17.53 seconds for 80 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 2 processed in 18.28 seconds, total token: 77358 (prompt token:68400, completion token:8958)\n",
            "Total processing time: 80.94 seconds for 160 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 3 processed in 17.04 seconds, total token: 77143 (prompt token:68400, completion token:8743)\n",
            "Total processing time: 143.08 seconds for 240 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 4 processed in 16.67 seconds, total token: 77131 (prompt token:68400, completion token:8731)\n",
            "Total processing time: 204.89 seconds for 320 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 5 processed in 16.72 seconds, total token: 76911 (prompt token:68400, completion token:8511)\n",
            "Total processing time: 266.77 seconds for 400 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 6 processed in 17.09 seconds, total token: 77374 (prompt token:68400, completion token:8974)\n",
            "Total processing time: 328.98 seconds for 480 images.\n",
            "Waiting 45 seconds to avoid rate limits\n",
            "Writting processed images in file: /content/FashionAIChatbot/processed_images_earrings.json\n",
            "Batch 7 processed in 1.37 seconds, total token: 2907 (prompt token:2565, completion token:342)\n",
            "Total processing time: 375.40 seconds for 483 images.\n",
            "Results have been saved to /content/FashionAIChatbot/results_earrings.json\n",
            "Total de imágenes procesadas: 483\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "import time\n",
        "\n",
        "total_imagenes_procesadas= 0\n",
        "# Variable global para almacenar el raw_output de cada batch\n",
        "raw_outputs_global = []\n",
        "max_retries = 3\n",
        "\n",
        "# File to store processed image paths to avoid duplicates\n",
        "processed_images_file = \"/content/FashionAIChatbot/processed_images_earrings.json\"\n",
        "\n",
        "# Load the list of already processed images\n",
        "if os.path.exists(processed_images_file):\n",
        "    with open(processed_images_file, 'r') as f:\n",
        "        processed_images = set(json.load(f))  # Use a set for fast lookups\n",
        "else:\n",
        "    processed_images = set()\n",
        "\n",
        "# JSON file to store the results\n",
        "results_file = \"/content/FashionAIChatbot/results_earrings.json\"\n",
        "\n",
        "#Load existing results if the file exists\n",
        "if os.path.exists(results_file):\n",
        "    with open(results_file, 'r') as f:\n",
        "        all_results = json.load(f)\n",
        "else:\n",
        "    all_results = []\n",
        "\n",
        "#print(all_results)\n",
        "\n",
        "def get_unprocessed_images(image_directory: str, max_images: int = 1000) -> List[str]:\n",
        "    \"\"\"Get all unprocessed images from the directory.\"\"\"\n",
        "    image_files = [\n",
        "        os.path.join(image_directory, f)\n",
        "        for f in os.listdir(image_directory)\n",
        "        if f.endswith(('.jpg', '.jpeg', '.png')) and os.path.join(image_directory, f) not in processed_images\n",
        "    ]\n",
        "    return image_files[:max_images]\n",
        "\n",
        "\n",
        "def prepare_batch_data(image_paths: List[str]) -> List[Dict[str, str]]:\n",
        "    \"\"\"Prepare batch data for LangChain.\"\"\"\n",
        "    batch_data = []\n",
        "    for image_path in image_paths:\n",
        "        image_data = encode_image(image_path)  # Encode image\n",
        "        batch_data.append({\n",
        "            \"language\": \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions(),\n",
        "            \"image_data\": image_data,\n",
        "            \"image_path\": image_path\n",
        "            #\"image_base64\": image_data  # Optionally add base64 string to results\n",
        "        })\n",
        "    return batch_data\n",
        "\n",
        "\n",
        "def process_image_batches_with_langchain(image_directory: str, batch_size: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Process images in batches, ensuring no duplicate processing.\"\"\"\n",
        "\n",
        "    # Start time for the entire process\n",
        "    start_time_total = time.time()\n",
        "\n",
        "    # Get all unprocessed images\n",
        "    unprocessed_images = get_unprocessed_images(image_directory, max_images=960)\n",
        "\n",
        "    global all_results  # Acceder a la variable global para agregar resultados\n",
        "    global total_imagenes_procesadas\n",
        "    global raw_outputs_global  # Variable global para almacenar los raw_outputs de cada batch\n",
        "    total_tokens = 0\n",
        "    total_prompt_tokens = 0\n",
        "    total_completion_tokens = 0\n",
        "\n",
        "    # Process images in batches\n",
        "    for i in range(0, len(unprocessed_images), batch_size):\n",
        "        batch = unprocessed_images[i:i + batch_size]\n",
        "        batch_data = prepare_batch_data(batch)\n",
        "        # print(f\"BATCH {i//batch_size + 1}: {len(batch_data)} imágenes procesadas.\")\n",
        "        #print(\"BATCH DATA:\", batch_data)\n",
        "        retries = 0  # Contador de reintentos\n",
        "\n",
        "        num_imagenes_procesadas = len(batch_data)\n",
        "\n",
        "        # Start time for the current batch\n",
        "        start_time_batch = time.time()\n",
        "\n",
        "        while retries < max_retries:\n",
        "            try:\n",
        "              with get_openai_callback() as cb:\n",
        "                # Use the LangChain .batch method to process the batch\n",
        "                results = chain.batch(batch_data)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                retries += 1  # Incrementar el contador de reintentos\n",
        "                print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
        "                if retries < max_retries:\n",
        "                    print(\"Retrying...\")\n",
        "                    #time.sleep(30)  # Esperar 30 segundos antes de reintentar\n",
        "                else:\n",
        "                    print(\"Max retries reached. Skipping this batch.\")\n",
        "                    continue  # Salir del bucle while y continuar con el siguiente batch\n",
        "        # Procesar los resultados si fueron exitosos\n",
        "        if retries < max_retries:\n",
        "            # Process the corrected results\n",
        "            for result, image_info in zip(results, batch_data):\n",
        "                #print(\"entro aqui\")\n",
        "                raw_output = None\n",
        "                try:\n",
        "                    # Get raw_output before parsing\n",
        "                    raw_output = result\n",
        "                    #raw_outputs_global.append(raw_output)  # Almacenar el raw_output en la variable global\n",
        "\n",
        "                    # Convert the corrected result to a Pydantic model\n",
        "                    result_dict = result.model_dump()\n",
        "                    result_dict[\"image_path\"] = image_info[\"image_path\"]\n",
        "                    all_results.append(result_dict)\n",
        "                except ValidationError as ve:\n",
        "                    print(f\"Validation error for image {image_info['image_path']}: {ve.errors()}\")\n",
        "                except Exception as e:\n",
        "                    # Indicar que la imagen no se procesó correctamente y mostrar el raw_output\n",
        "                    print(f\"Error parsing result for image {image_info['image_path']}: {e}\")\n",
        "                    print(f\"Raw output for this image: {raw_output}\")\n",
        "\n",
        "            # Sumar el uso de tokens, prompt y completion\n",
        "            total_tokens += cb.total_tokens\n",
        "            total_prompt_tokens += cb.prompt_tokens\n",
        "            total_completion_tokens += cb.completion_tokens\n",
        "\n",
        "            # Update the list of processed images\n",
        "            processed_images.update(batch)\n",
        "\n",
        "            # Save the updated processed images list\n",
        "            with open(processed_images_file, 'w') as f:\n",
        "                json.dump(list(processed_images), f, indent=2)\n",
        "                print(f\"Writting processed images in file: {processed_images_file}\")\n",
        "\n",
        "            # End time for the batch\n",
        "            end_time_batch = time.time()\n",
        "            batch_duration = end_time_batch - start_time_batch\n",
        "\n",
        "            print(f\"Batch {i // batch_size + 1} processed in {batch_duration:.2f} seconds, total token: {total_tokens} (prompt token:{total_prompt_tokens}, completion token:{total_completion_tokens})\")\n",
        "\n",
        "            total_imagenes_procesadas += num_imagenes_procesadas\n",
        "\n",
        "            #Reinicio cantidad tokens:\n",
        "            total_tokens = 0\n",
        "            total_prompt_tokens = 0\n",
        "            total_completion_tokens = 0\n",
        "\n",
        "        # End time for the entire process\n",
        "        end_time_total = time.time()\n",
        "        total_duration = end_time_total - start_time_total\n",
        "        print(f\"Total processing time: {total_duration:.2f} seconds for {total_imagenes_procesadas} images.\")\n",
        "\n",
        "        # Check if it's the last batch, if not, wait for 30 seconds\n",
        "        if i + batch_size < len(unprocessed_images):\n",
        "            time.sleep(45)  # Wait for 30 seconds before processing the next batch\n",
        "            print(\"Waiting 45 seconds to avoid rate limits\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_directory = \"/content/Re-PolyVore/earrings\"\n",
        "batch_size = 80\n",
        "results = process_image_batches_with_langchain(image_directory, batch_size)\n",
        "\n",
        "# Save results as JSON in a file\n",
        "with open(results_file, \"w\") as json_file:\n",
        "    json.dump(all_results, json_file, indent=2)\n",
        "\n",
        "print(f\"Results have been saved to {results_file}\")\n",
        "\n",
        "# Imprimir el raw_output al final de la ejecución\n",
        "# print(f\"Raw outputs from all batches: {raw_outputs_global}\")\n",
        "\n",
        "# Al final, imprimir el total de imágenes procesadas\n",
        "print(f\"Total de imágenes procesadas: {total_imagenes_procesadas}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vriO610ndq1B",
        "outputId": "3d0abb5c-974c-47ed-94c6-e3776494214e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FashionAIChatbot\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FashionAIChatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9e4cUaO7PzX",
        "outputId": "d8dd81c3-9e5a-455d-9d0f-d0da1d514e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 41e242d] earrings completed (4563 images)\n",
            " 4 files changed, 59323 insertions(+), 227660 deletions(-)\n",
            " delete mode 100644 processed_images.json\n",
            " create mode 100644 processed_images_earrings.json\n",
            " delete mode 100644 results.json\n",
            " create mode 100644 results_earrings.json\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 341.97 KiB | 2.85 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 1 local object.\u001b[K\n",
            "To https://github.com/amandamaduro/FashionAIChatbot.git\n",
            "   4305adb..41e242d  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git add processed_images_earrings.json results_earrings.json\n",
        "!git commit -m \"earrings completed (4563 images)\"\n",
        "!git push"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CeKo1CNww99A",
        "v7bwf1D2xSBB",
        "L0U3huDykUPm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}