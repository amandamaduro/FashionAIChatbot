{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Repo de Git"
      ],
      "metadata": {
        "id": "u4gOi3RL6crB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!git clone https://github.com/amandamaduro/FashionAIChatbot.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "1PnS9UT56j1f",
        "outputId": "59e3fd02-ed6d-43ba-8322-3f871b273e9d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FashionAIChatbot'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), 21.53 KiB | 612.00 KiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "%cd /content/FashionAIChatbot/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5gV8HQm7x7H",
        "outputId": "07ee1d4a-ef3c-4233-a447-2b977dd2d891",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FashionAIChatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eptlougrwhza"
      },
      "source": [
        "# Extraer datos de google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OWHp8GeJvF1i"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"/content/drive/MyDrive/FashionAIChatbot/Re-PolyVore.tar\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ohdjih2lc1"
      },
      "source": [
        "Verificar que esten todas las imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrg5f8PuwyGR",
        "outputId": "090618c0-75d2-4cce-dec9-8aacb7c3fa4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the directory: 17512\n"
          ]
        }
      ],
      "source": [
        "# prompt: count images from a directory\n",
        "\n",
        "import os\n",
        "\n",
        "def count_images_in_directory(directory):\n",
        "  \"\"\"Counts the number of image files in a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The path to the directory.\n",
        "\n",
        "  Returns:\n",
        "    The number of image files in the directory.\n",
        "  \"\"\"\n",
        "  image_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\"]  # Add more if needed\n",
        "  count = 0\n",
        "  for filename in os.listdir(directory):\n",
        "    if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "# Example usage:\n",
        "directory_path = \"/content/Re-PolyVore/bag\"  # Replace with your directory path\n",
        "image_count = count_images_in_directory(directory_path)\n",
        "print(f\"Number of images in the directory: {image_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdQJL4JN2txu"
      },
      "source": [
        "# **Generacion de descripciones de productos de moda**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QBiudBjy2hUE",
        "outputId": "9716753b-9f7e-4fa8-b2d5-93200ea7559d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
            "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core)\n",
            "  Downloading langsmith-0.1.127-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
            "Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.5-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.127-py3-none-any.whl (291 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.5 langchain-openai-0.2.0 langsmith-0.1.127 openai-1.47.1 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSl-ZnOq5sqA"
      },
      "source": [
        "1. Cargar la imagen del producto en formato base64 data URI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l79cJ5pp5qDg"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "\"\"\"Function to encode images in base64 data URI\n",
        "parameters: image path\n",
        "return: encoded based64 text version\"\"\"\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "#print(encode_image(\"/content/Re-PolyVore/bag/100002074_3.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3v1YzxFDN-uI",
        "outputId": "e00b5777-3775-4b32-af40-9589c890c062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j8BWketRwZvh",
        "outputId": "6a76c39d-7743-4dd5-9b1b-ee23f52e8c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.5)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.127)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.3.0 langchain-text-splitters-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHxHKk42wHB",
        "outputId": "c20bd1ae-5b22-4a71-fbb3-86f70a028c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.127)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsMQ4RR08P1W"
      },
      "source": [
        "##OPEN AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeXjlV0cMmi4",
        "outputId": "62793ea3-52bc-4d98-9bb4-29349d8e8c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/OPENAI_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RccS0vY3v1pn"
      },
      "source": [
        "GPT-4o Prompt mas detallado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YoozKyUJ__1M",
        "outputId": "0c24c4b6-5436-4fbb-d7ad-b5e8c982c57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8705\n",
            "\tPrompt Tokens: 8555\n",
            "\tCompletion Tokens: 150\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00137325\n",
            "**Product Name:** Michael Kors Croc-Embossed Tote\n",
            "\n",
            "**Product Description:** This luxurious tote features a striking croc-embossed design, exuding sophistication and elegance. The bag is accented with gold-tone hardware, showcasing the Michael Kors logo prominently on the front. It includes dual top handles for easy carrying and a detachable shoulder strap for versatility. Its spacious interior allows for ample storage, making it perfect for both everyday use and special occasions.\n",
            "\n",
            "**Product Category:** Handbag/Tote Bag\n",
            "\n",
            "**Style:** Elegant, Modern\n",
            "\n",
            "**Materials:** Faux leather with a croc-embossed finish, gold-tone metal hardware\n",
            "\n",
            "**Dominant Colors:** Rich brown tones with a gradient effect\n",
            "\n",
            "**Fit and Silhouette:** Structured silhouette\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product. Include the product name, product description, product category, style, materials, dominant colors, fit and silhoutte, suitable occasion and recommended season: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bha-if9Fv-hz"
      },
      "source": [
        "GPT-4o-mini. Prompt simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KoESRMHm4rch",
        "outputId": "2517b51c-78d8-42be-a896-7582bb9712e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 8630\n",
            "\tPrompt Tokens: 8525\n",
            "\tCompletion Tokens: 105\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0013417499999999998\n",
            "This watch from Daniel Wellington features a classic and elegant design, characterized by its minimalist aesthetic. It has a clean white dial with thin gold hour markers and hands, contributing to its sophisticated appearance. The case is gold-toned, adding a touch of luxury, while the black leather strap provides a timeless contrast, ensuring versatility for various occasions. This watch combines functionality with style, making it suitable for both casual and formal outfits. Its understated elegance makes it a perfect accessory for anyone looking to enhance their wardrobe with a chic timepiece.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=150)\n",
        "image_data = encode_image(\"/content/Re-PolyVore/watches/139069134_7.jpg\")\n",
        "message = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a professional stylist and fashion consultant\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "]\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke(message)\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXvTuoFp8Wyc"
      },
      "source": [
        "##Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XvCFPB9g0wJo",
        "outputId": "ad4c26b5-72a0-466c-fea8-c3b9f1684b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.127)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNoH00qf03mj",
        "outputId": "7ed55ec2-fb8e-44d6-8b2a-33117860bbaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv(\"/content/GOOGLE_API_KEY.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-rNFXYCvShl9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "# image_path= \"/content/prueba/4207948.jpg\"\n",
        "\n",
        "# image_data = encode_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JAJPZ0cBLfrg"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field, field_validator, ValidationError, model_validator\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "from typing import Any, Dict\n",
        "import re\n",
        "import json\n",
        "\n",
        "# We define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"The name of the fashion product shown in the image\")\n",
        "    description: str = Field(description=\"The description of the fashion product shown in the image\")\n",
        "    category: str = Field(description=\"The category of the fashion product shown in the image (e.g. dress, pants, blouse, jacket, etc)\")\n",
        "    style: str = Field(description=\"The style of the fashion product shown in the image, you can choose more than one (e.g. formal, casual, sporty, etc.)\")\n",
        "    materials: str = Field(description=\"The materials of the fashion product shown in the image (e.g. cotton, silk, leather, etc.)\")\n",
        "    color: str = Field(description=\"The dominant colors of the fashion product shown in the image\")\n",
        "    fit_silhouette: str = Field(description=\"The fit and silhouette of the fashion product shown in the image (e.g. fitted, loose, straight, etc.). If nothing applies, set it to N/A\")\n",
        "    occasion: str = Field(description=\"The suitable occasion for the fashion product shown in the image, you can choose more than one (e.g. formal event, everyday wear, vacation, etc.)\")\n",
        "    season: str = Field(description=\"The recommended season for the fashion product shown in the image, you can choose more than one (e.g. spring, summer, fall, winter, all seasons)\")\n",
        "\n",
        "    @field_validator('*', mode=\"before\")\n",
        "    @classmethod\n",
        "    def validate_strings(cls, value: Any, field: Any) -> str:\n",
        "        \"\"\"Valida que todos los campos sean strings, y convierte si es necesario.\"\"\"\n",
        "        if isinstance(value, list):\n",
        "            # Aquí manejamos la conversión de listas a strings\n",
        "            value = ', '.join(value)\n",
        "\n",
        "        if not isinstance(value, str):\n",
        "            raise ValueError(f\"The field '{field.name}' must be a string.\")\n",
        "\n",
        "        # Reemplazar operadores de concatenación inválidos (ejemplo: \" + \")\n",
        "        value_str = re.sub(r'\\s*\\+\\s*', ' ', value)\n",
        "\n",
        "        # Escapar comillas dobles dentro de strings\n",
        "        return value_str.replace('\"', '\\\"')\n",
        "\n",
        "    # \"\"\"@classmethod\n",
        "    # def validate_fashion_products(cls, products: List['FashionProduct']) -> List['FashionProduct']:\n",
        "    #     \"\"\"\n",
        "    #     Valida y corrige una lista de objetos FashionProduct.\n",
        "\n",
        "    #     :param products: Lista de objetos FashionProduct.\n",
        "    #     :return: Lista de objetos FashionProduct validados.\n",
        "    #     \"\"\"\n",
        "    #     validated_products = []\n",
        "    #     for product in products:\n",
        "    #         try:\n",
        "    #             # Convertir el objeto FashionProduct a un diccionario\n",
        "    #             product_dict = product.model_dump()\n",
        "\n",
        "    #             # Aplicar validate_strings a cada campo\n",
        "    #             for field, value in product_dict.items():\n",
        "    #                 product_dict[field] = cls.validate_strings(value, field)\n",
        "\n",
        "    #             # Crear una nueva instancia de FashionProduct con los datos validados\n",
        "    #             validated_product = cls(**product_dict)\n",
        "    #             validated_products.append(validated_product)\n",
        "    #         except ValidationError as e:\n",
        "    #             print(f\"Validation error for product {product['name']}: {e}\")\n",
        "    #         except Exception as e:\n",
        "    #             print(f\"Unexpected error for product {product['name']}: {e}\")\n",
        "\n",
        "    #     return validated_products\n",
        "\n",
        "    # @model_validator(mode=\"before\")\n",
        "    # \"\"\"@classmethod\n",
        "    # def pre_validate(cls, values: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    #     \"\"\"Método de validación que se ejecuta antes de la validación de Pydantic.\"\"\"\n",
        "\n",
        "    #     products_to_validate = [values]  # Aquí podrías recolectar múltiples entradas si fuera necesario\n",
        "    #     validated_products = cls.validate_fashion_products(products_to_validate)\n",
        "\n",
        "    #     # Puedes retornar el primer producto validado si es que validas una lista\n",
        "    #     if validated_products:\n",
        "    #         return validated_products[0].dict()  # Retorna el primer producto validado como un dict\n",
        "\n",
        "    #     return values  # Si no hay productos, retornar los valores originales\n",
        "\n",
        "#-----------------------------PARA PROBAR EL PYDANTIC MODEL----------------------------------------\n",
        "# Ejemplo de uso\n",
        "# ejemplos = [\n",
        "#     FashionProduct(name='Fendi Peekaboo' + 'ISeeU Mini Bag', description='This Fendi Peekaboo ISeeU Mini Bag is crafted from pink leather and features a top handle, a detachable and adjustable shoulder strap, a top zip closure, a signature peekaboo flap closure, silver-tone hardware, a front logo plaque, and a crystal-embellished charm.', category='Handbag', style='Casual', materials='Leather', color='Pink', fit_silhouette='N/A', occasion='Everyday, Casual', season='All Seasons'),\n",
        "#     FashionProduct(name='Clear Acrylic Clutch', description='A clear acrylic clutch with a gold chain strap and a gold clasp. It is perfect for carrying your essentials for a night out.', category='Clutch', style=['Formal', 'Evening'], materials='Acrylic, Metal', color='Clear, Gold', fit_silhouette='N/A', occasion='Formal Event, Night Out', season='All Seasons'),\n",
        "#     FashionProduct(name='Kotur Clutch', description='This clutch is \"made\" of black and white striped acrylic with a gold bird-shaped clasp. It is perfect for evening wear.', category='Clutch', style='Formal', materials='Acrylic, Gold', color='Black and White', fit_silhouette='N/A', occasion='Formal event, Evening wear', season='All seasons'),\n",
        "#     FashionProduct(name='Quilted Patent Leather Tote Bag', description='This tote bag is made of white patent leather with a quilted design. It features a top handle and a detachable chain strap. It has a gold-tone hardware and a heart-shaped charm on the front.', category='Handbag', style='Classic', materials='Patent Leather', color='White', fit_silhouette='N/A', occasion='Everyday, Formal, Work', season='All Seasons'),\n",
        "#     FashionProduct(name='Leather Chain Strap Crossbody Bag', description='This is a small crossbody bag with a chain strap. It is made of brown leather and has a flap closure. The bag is perfect for everyday wear and can be dressed up or down.', category='Bag', style='Casual', materials='Leather', color='Brown', fit_silhouette='N/A', occasion='Everyday, Casual', season='All Seasons')\n",
        "# ]\n",
        "\n",
        "# # Imprimir los productos validados\n",
        "# for product in ejemplos:\n",
        "#     print(product.model_dump_json(indent=2))\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"You are a professional stylist and fashion consultant. Return the requested response fashion product object in {language}. You must use JSON Format. \\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# with get_openai_callback() as cb:\n",
        "#   print(chain.invoke({\"language\":\"English\",\n",
        "#                     \"format_instructions\":parser.get_format_instructions(),\n",
        "#                     \"image_data\":image_data}).model_dump_json(indent=2),)\n",
        "#   #print(response)\n",
        "#   print(cb)\n",
        "\n",
        "# print(chain.invoke({\"language\":\"English\",\n",
        "#                     \"format_instructions\":parser.get_format_instructions(),\n",
        "#                     \"image_data\":image_data}).model_dump_json(indent=2),)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JBq-OhJ0sfV"
      },
      "source": [
        "##Prompt Simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-_15-E71gSy",
        "outputId": "3478bec3-41d4-43eb-bb9f-105962ed1e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens Used: 351\n",
            "\tPrompt Tokens: 274\n",
            "\tCompletion Tokens: 77\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0\n",
            "This classic Daniel Wellington watch is a timeless piece that exudes understated elegance. The rose gold case and hands complement the crisp white dial, creating a sophisticated and refined look. The black leather strap adds a touch of contemporary edge, making it perfect for both casual and formal occasions. This versatile watch is a must-have for any fashion-conscious individual who appreciates minimalist design and timeless style. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_community.callbacks import get_openai_callback\n",
        "\n",
        "#image_path= \"/content/Re-PolyVore/bag/100002074_3.jpg\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", max_output_tokens=150)\n",
        "image_data = encode_image(image_path)\n",
        "message = HumanMessage(\n",
        "        content=[\n",
        "          {\"type\": \"text\", \"text\": \"You are a professional stylist and fashion consultant. Describe this fashion product: \"},\n",
        "          {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "          },\n",
        "      ],\n",
        "    )\n",
        "with get_openai_callback() as cb:\n",
        "  response = llm.invoke([message])\n",
        "  print(cb)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0U3huDykUPm"
      },
      "source": [
        "##**En español**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3c0T4j6HkQ2_",
        "outputId": "03b454ba-2891-4751-9f92-5a6a95fd21ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-d0c3c1083ca9>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m\"language\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Spanish\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Set the output language to Spanish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"format_instructions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;34m\"image_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     })\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure that response is formatted as JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_data' is not defined"
          ]
        }
      ],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define a Pydantic model that will be used to parse the output of the model\n",
        "class FashionProduct(BaseModel):\n",
        "    name: str = Field(description=\"El nombre del producto de moda mostrado en la imagen\")\n",
        "    description: str = Field(description=\"La descripción del producto de moda mostrado en la imagen\")\n",
        "    category: str = Field(description=\"La categoría del producto de moda mostrado en la imagen (ej. vestido, pantalones, blusa, chaqueta, etc.)\")\n",
        "    style: str = Field(description=\"El estilo del producto de moda mostrado en la imagen, puede elegir más de uno (ej. formal, casual, deportivo, etc.)\")\n",
        "    materials: str = Field(description=\"Los materiales del producto de moda mostrado en la imagen (ej. algodón, seda, cuero, etc.)\")\n",
        "    color: str = Field(description=\"Los colores dominantes del producto de moda mostrado en la imagen\")\n",
        "    fit_silhouette: str = Field(description=\"El ajuste y la silueta del producto de moda mostrado en la imagen (ej. ajustado, suelto, recto, etc.)\")\n",
        "    occasion: str = Field(description=\"La ocasión adecuada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. evento formal, uso diario, vacaciones, etc.)\")\n",
        "    season: str = Field(description=\"La temporada recomendada para el producto de moda mostrado en la imagen, puede elegir más de una (ej. primavera, verano, otoño, invierno, todas las temporadas)\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=FashionProduct)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\"Eres un estilista profesional y asesor de moda. Devuelve las descripciones del producto de moda solicitado en {language}.\\n'{format_instructions}'\\n\"\n",
        "    ),\n",
        "    (\n",
        "        \"human\", [\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "])\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    # Invoke the chain with the language set to Spanish\n",
        "    response = chain.invoke({\n",
        "        \"language\": \"Spanish\",  # Set the output language to Spanish\n",
        "        \"format_instructions\": parser.get_format_instructions(),\n",
        "        \"image_data\": image_data\n",
        "    })\n",
        "    print(response.model_dump_json(indent=2))  # Ensure that response is formatted as JSON\n",
        "    print(cb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHrw1YM81jDz"
      },
      "source": [
        "##Procesamiento en Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk2O4Rg0DSEW"
      },
      "source": [
        "\n",
        "Procesamiento paralelo con verificacion de que en ningun batch hayan duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr3tPMPpDXDz",
        "outputId": "641ef044-7b54-43bb-ef5d-bc4738e0f4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 processed\n",
            "Waiting 30 seconds to avoid rate limits\n",
            "Error processing batch 2: Invalid json output: ```json\n",
            "{\"name\": \"Fendi  \" \"Mini  \" \"Fur  \" \"Clutch\", \"description\": \"This clutch is a small, rectangular bag made of soft pink fur. It has a gold skull clasp with red jewels on the front. It is a perfect size for carrying essentials for an evening out.\", \"category\": \"Clutch\", \"style\": \"Formal\", \"materials\": \"Fur\", \"color\": \"Pink\", \"fit_silhouette\": \"N/A\", \"occasion\": \"Evening\", \"season\": \"All seasons\"}\n",
            "```\n",
            "Retrying in 30 seconds...\n",
            "Error processing batch 2: Failed to parse FashionProduct from completion {\"name\": \"Fendi  \"}. Got: 8 validation errors for FashionProduct\n",
            "description\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "category\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "style\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "materials\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "color\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "fit_silhouette\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "occasion\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "season\n",
            "  Field required [type=missing, input_value={'name': 'Fendi  '}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
            "Retrying in 30 seconds...\n",
            "Batch 2 processed\n",
            "Results have been saved to results.json\n",
            "Total de imágenes procesadas: 300\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "import time\n",
        "\n",
        "total_imagenes_procesadas= 0\n",
        "# Variable global para almacenar el raw_output de cada batch\n",
        "raw_outputs_global = []\n",
        "max_retries = 3\n",
        "\n",
        "# File to store processed image paths to avoid duplicates\n",
        "processed_images_file = \"processed_images.json\"\n",
        "\n",
        "# Load the list of already processed images\n",
        "if os.path.exists(processed_images_file):\n",
        "    with open(processed_images_file, 'r') as f:\n",
        "        processed_images = set(json.load(f))  # Use a set for fast lookups\n",
        "else:\n",
        "    processed_images = set()\n",
        "\n",
        "# JSON file to store the results\n",
        "results_file = \"results.json\"\n",
        "\n",
        "#Load existing results if the file exists\n",
        "if os.path.exists(results_file):\n",
        "    with open(results_file, 'r') as f:\n",
        "        all_results = json.load(f)\n",
        "else:\n",
        "    all_results = []\n",
        "\n",
        "#print(all_results)\n",
        "\n",
        "def get_unprocessed_images(image_directory: str, max_images: int = 1000) -> List[str]:\n",
        "    \"\"\"Get all unprocessed images from the directory.\"\"\"\n",
        "    image_files = [\n",
        "        os.path.join(image_directory, f)\n",
        "        for f in os.listdir(image_directory)\n",
        "        if f.endswith(('.jpg', '.jpeg', '.png')) and os.path.join(image_directory, f) not in processed_images\n",
        "    ]\n",
        "    return image_files[:max_images]\n",
        "\n",
        "\n",
        "def prepare_batch_data(image_paths: List[str]) -> List[Dict[str, str]]:\n",
        "    \"\"\"Prepare batch data for LangChain.\"\"\"\n",
        "    batch_data = []\n",
        "    for image_path in image_paths:\n",
        "        image_data = encode_image(image_path)  # Encode image\n",
        "        batch_data.append({\n",
        "            \"language\": \"English\",\n",
        "            \"format_instructions\": parser.get_format_instructions(),\n",
        "            \"image_data\": image_data,\n",
        "            \"image_path\": image_path\n",
        "            #\"image_base64\": image_data  # Optionally add base64 string to results\n",
        "        })\n",
        "    return batch_data\n",
        "\n",
        "\n",
        "def process_image_batches_with_langchain(image_directory: str, batch_size: int = 5) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Process images in batches, ensuring no duplicate processing.\"\"\"\n",
        "\n",
        "    # Get all unprocessed images\n",
        "    unprocessed_images = get_unprocessed_images(image_directory, max_images=300)\n",
        "\n",
        "    global all_results  # Acceder a la variable global para agregar resultados\n",
        "    global total_imagenes_procesadas\n",
        "    global raw_outputs_global  # Variable global para almacenar los raw_outputs de cada batch\n",
        "    total_tokens = 0\n",
        "    total_cost = 0.0\n",
        "\n",
        "    # Process images in batches\n",
        "    for i in range(0, len(unprocessed_images), batch_size):\n",
        "        batch = unprocessed_images[i:i + batch_size]\n",
        "        batch_data = prepare_batch_data(batch)\n",
        "        # print(f\"BATCH {i//batch_size + 1}: {len(batch_data)} imágenes procesadas.\")\n",
        "        #print(\"BATCH DATA:\", batch_data)\n",
        "        retries = 0  # Contador de reintentos\n",
        "\n",
        "        num_imagenes_procesadas = len(batch_data)\n",
        "        while retries < max_retries:\n",
        "          try:\n",
        "              # Use the LangChain .batch method to process the batch\n",
        "              results = chain.batch(batch_data)\n",
        "              break\n",
        "          except Exception as e:\n",
        "              retries += 1  # Incrementar el contador de reintentos\n",
        "              print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
        "              if retries < max_retries:\n",
        "                  print(\"Retrying in 30 seconds...\")\n",
        "                  time.sleep(30)  # Esperar 30 segundos antes de reintentar\n",
        "              else:\n",
        "                  print(\"Max retries reached. Skipping this batch.\")\n",
        "                  continue  # Salir del bucle while y continuar con el siguiente batch\n",
        "        # Procesar los resultados si fueron exitosos\n",
        "        if retries < max_retries:\n",
        "          # Process the corrected results\n",
        "          for result, image_info in zip(results, batch_data):\n",
        "              #print(\"entro aqui\")\n",
        "              raw_output = None\n",
        "              try:\n",
        "                  # Get raw_output before parsing\n",
        "                  raw_output = result\n",
        "                  #raw_outputs_global.append(raw_output)  # Almacenar el raw_output en la variable global\n",
        "\n",
        "                  # Convert the corrected result to a Pydantic model\n",
        "                  result_dict = result.model_dump()\n",
        "                  result_dict[\"image_path\"] = image_info[\"image_path\"]\n",
        "                  all_results.append(result_dict)\n",
        "              except ValidationError as ve:\n",
        "                  print(f\"Validation error for image {image_info['image_path']}: {ve.errors()}\")\n",
        "              except Exception as e:\n",
        "                  # Indicar que la imagen no se procesó correctamente y mostrar el raw_output\n",
        "                  print(f\"Error parsing result for image {image_info['image_path']}: {e}\")\n",
        "                  print(f\"Raw output for this image: {raw_output}\")\n",
        "\n",
        "        # Update the list of processed images\n",
        "        processed_images.update(batch)\n",
        "\n",
        "        # Save the updated processed images list\n",
        "        with open(processed_images_file, 'w') as f:\n",
        "            json.dump(list(processed_images), f, indent=2)\n",
        "\n",
        "        print(f\"Batch {i // batch_size + 1} processed\")\n",
        "        # Check if it's the last batch, if not, wait for 30 seconds\n",
        "        if i + batch_size < len(unprocessed_images):\n",
        "            time.sleep(30)  # Wait for 30 seconds before processing the next batch\n",
        "            print(\"Waiting 30 seconds to avoid rate limits\")\n",
        "\n",
        "\n",
        "        total_imagenes_procesadas += num_imagenes_procesadas\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_directory = \"/content/Re-PolyVore/bag\"\n",
        "batch_size = 200\n",
        "results = process_image_batches_with_langchain(image_directory, batch_size)\n",
        "\n",
        "\n",
        "# no_procesadas=get_unprocessed_images(image_directory)\n",
        "# print(\"resultado de get_unprocessed_images: \", no_procesadas)\n",
        "\n",
        "#\n",
        "\n",
        "# for i in range(0, len(no_procesadas), batch_size):\n",
        "#     batch = no_procesadas[i:i + batch_size]\n",
        "#     batch_data = prepare_batch_data(batch)\n",
        "\n",
        "#     print(f\"BATCH {i//batch_size + 1}: {num_imagenes_procesadas} imágenes procesadas.\")\n",
        "#     print(\"BATCH DATA:\", batch_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Save results as JSON in a file\n",
        "with open(results_file, \"w\") as json_file:\n",
        "    json.dump(all_results, json_file, indent=2)\n",
        "\n",
        "print(f\"Results have been saved to {results_file}\")\n",
        "\n",
        "# Imprimir el raw_output al final de la ejecución\n",
        "# print(f\"Raw outputs from all batches: {raw_outputs_global}\")\n",
        "\n",
        "# Al final, imprimir el total de imágenes procesadas\n",
        "print(f\"Total de imágenes procesadas: {total_imagenes_procesadas}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add processed_images.json results.json\n",
        "!git commit -m \"Added processed_images.json and results.json (definitive files)\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "e9e4cUaO7PzX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/FashionChatbot.ipynb /content/FashionAIChatbot/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPcuufj3DrHL",
        "outputId": "f5bdaebe-3035-4b29-a3f8-cc664c59d63d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/FashionChatbot.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add FashionChatbot.ipynb\n",
        "!git commit -m \"Fix errors in process_image_batches_with_langchain\"\n",
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ILUfhSCprL",
        "outputId": "07b6497b-80a9-432e-e3b6-81af306ff799"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}